{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/text_label.csv\",  encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into labeled and unlabeled data\n",
    "labeled_data = df[df['LABEL'].notna()]\n",
    "unlabeled_data = df[df['LABEL'].isna()]\n",
    "\n",
    "# Split labeled data into train and validation sets\n",
    "train_data, val_data = train_test_split(labeled_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train = vectorizer.fit_transform(train_data['FOI_TEXT'])\n",
    "X_val = vectorizer.transform(val_data['FOI_TEXT'])\n",
    "X_unlabeled = vectorizer.transform(unlabeled_data['FOI_TEXT'])\n",
    "\n",
    "y_train = train_data['LABEL']\n",
    "y_val = val_data['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 5., 2., 3.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['LABEL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDR_REPORT_KEY</th>\n",
       "      <th>MDR_TEXT_KEY</th>\n",
       "      <th>TEXT_TYPE_CODE</th>\n",
       "      <th>PATIENT_SEQUENCE_NUMBER</th>\n",
       "      <th>FOI_TEXT</th>\n",
       "      <th>DATE_RECEIVED</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6383024</td>\n",
       "      <td>106903842</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...</td>\n",
       "      <td>6/3/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6383024</td>\n",
       "      <td>106903843</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...</td>\n",
       "      <td>6/3/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6383024</td>\n",
       "      <td>109652829</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>IF INFORMATION IS PROVIDED IN THE FUTURE, A SU...</td>\n",
       "      <td>6/3/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6383024</td>\n",
       "      <td>69202956</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>MANUFACTURER REFERENCE NUMBER: (B)(4). INCIDEN...</td>\n",
       "      <td>6/3/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6343125</td>\n",
       "      <td>107384375</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>IF INFORMATION IS PROVIDED IN THE FUTURE, A SU...</td>\n",
       "      <td>20/2/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>10722253</td>\n",
       "      <td>212603921</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>BASED ON THE INVESTIGATION, THE DEVICE WAS NOT...</td>\n",
       "      <td>22/10/2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>10722253</td>\n",
       "      <td>320662340</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>THIS REPORT IS A DUPLICATE REPORT TO 2183959-2...</td>\n",
       "      <td>22/10/2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>10722574</td>\n",
       "      <td>212684512</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>IT WAS REPORTED THAT THE PATIENT UNDERWENT A R...</td>\n",
       "      <td>22/10/2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>10732217</td>\n",
       "      <td>212963377</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>THE EXACT EVENT DATE IS UNKNOWN.</td>\n",
       "      <td>25/10/2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>10732217</td>\n",
       "      <td>212963378</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>IT WAS REPORTED THAT THE PATIENT HAD AN ATTEMP...</td>\n",
       "      <td>25/10/2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MDR_REPORT_KEY  MDR_TEXT_KEY TEXT_TYPE_CODE  PATIENT_SEQUENCE_NUMBER  \\\n",
       "0            6383024     106903842              N                        1   \n",
       "1            6383024     106903843              D                        1   \n",
       "2            6383024     109652829              N                        1   \n",
       "3            6383024      69202956              N                        1   \n",
       "5            6343125     107384375              N                        1   \n",
       "...              ...           ...            ...                      ...   \n",
       "3588        10722253     212603921              N                        1   \n",
       "3590        10722253     320662340              N                        0   \n",
       "3592        10722574     212684512              D                        1   \n",
       "3594        10732217     212963377              N                        1   \n",
       "3595        10732217     212963378              D                        1   \n",
       "\n",
       "                                               FOI_TEXT DATE_RECEIVED  LABEL  \n",
       "0     BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...      6/3/2017    1.0  \n",
       "1     BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...      6/3/2017    1.0  \n",
       "2     IF INFORMATION IS PROVIDED IN THE FUTURE, A SU...      6/3/2017    1.0  \n",
       "3     MANUFACTURER REFERENCE NUMBER: (B)(4). INCIDEN...      6/3/2017    1.0  \n",
       "5     IF INFORMATION IS PROVIDED IN THE FUTURE, A SU...     20/2/2017    1.0  \n",
       "...                                                 ...           ...    ...  \n",
       "3588  BASED ON THE INVESTIGATION, THE DEVICE WAS NOT...    22/10/2020    1.0  \n",
       "3590  THIS REPORT IS A DUPLICATE REPORT TO 2183959-2...    22/10/2020    1.0  \n",
       "3592  IT WAS REPORTED THAT THE PATIENT UNDERWENT A R...    22/10/2020    1.0  \n",
       "3594                   THE EXACT EVENT DATE IS UNKNOWN.    25/10/2020    1.0  \n",
       "3595  IT WAS REPORTED THAT THE PATIENT HAD AN ATTEMP...    25/10/2020    1.0  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[labeled_data['LABEL'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9202,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the classifier on labeled data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "initial_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/text_label.csv\",  encoding='latin-1')\n",
    "X = data['FOI_TEXT']  # Text data\n",
    "y = data['LABEL']  # Labels\n",
    "\n",
    "# Split into labeled and unlabeled\n",
    "X_labeled = X[y.notnull()]\n",
    "y_labeled = y[y.notnull()]\n",
    "X_unlabeled = X[y.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the labeled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42, stratify=y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Limit to top 1000 features for efficiency\n",
    "X_labeled_vec = vectorizer.fit_transform(X_labeled)\n",
    "X_unlabeled_vec = vectorizer.transform(X_unlabeled)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200)\n",
    "\n",
    "# Self-training loop\n",
    "while True:\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Get probability predictions on the unlabeled data\n",
    "    y_pred_proba = model.predict_proba(X_unlabeled_vec)\n",
    "\n",
    "    # Get indices of samples with high confidence predictions\n",
    "    high_confidence_indices = np.where(np.max(y_pred_proba, axis=1) > 0.90)[0]\n",
    "\n",
    "    if len(high_confidence_indices) == 0:\n",
    "        break  # Exit if no high-confidence predictions\n",
    "\n",
    "    # Get the corresponding text and predicted labels\n",
    "    X_high_conf = X_unlabeled.iloc[high_confidence_indices]\n",
    "    y_high_conf = np.argmax(y_pred_proba[high_confidence_indices], axis=1)\n",
    "\n",
    "    # Append high-confidence samples to the labeled data\n",
    "    X_train = pd.concat([X_train, X_high_conf])\n",
    "    y_train = pd.concat([y_train, pd.Series(y_high_conf)])\n",
    "\n",
    "    # Remove high-confidence samples from the unlabeled data\n",
    "    X_unlabeled = X_unlabeled.drop(X_high_conf.index)\n",
    "\n",
    "    # Re-vectorize the updated training data\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_unlabeled_vec = vectorizer.transform(X_unlabeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      1.00      0.90        44\n",
      "         1.0       0.50      0.40      0.44        25\n",
      "         2.0       0.47      0.47      0.47        15\n",
      "         3.0       0.31      0.31      0.31        16\n",
      "         4.0       0.83      0.38      0.53        13\n",
      "         5.0       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.65       125\n",
      "   macro avg       0.61      0.57      0.57       125\n",
      "weighted avg       0.64      0.65      0.63       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=np.unique(y_test), \n",
    "            yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xt/7gvkdnw143dgfgsp73bsn11w0000gn/T/ipykernel_7159/706233443.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data[\"LABEL\"] = labeled_data[\"LABEL\"].astype(int)\n",
      "/var/folders/xt/7gvkdnw143dgfgsp73bsn11w0000gn/T/ipykernel_7159/706233443.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data['encoded_label'] = label_encoder.fit_transform(labeled_data['LABEL'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split into labeled and unlabeled data\n",
    "labeled_data = df[df['LABEL'].notna()]\n",
    "unlabeled_data = df[df['LABEL'].isna()]\n",
    "\n",
    "labeled_data[\"LABEL\"] = labeled_data[\"LABEL\"].astype(int)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labeled_data['encoded_label'] = label_encoder.fit_transform(labeled_data['LABEL'])\n",
    "# # Split labeled data into train and validation sets\n",
    "# train_data, val_data = train_test_split(labeled_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Preprocess the text data using TF-IDF\n",
    "# vectorizer = TfidfVectorizer(max_features=10000)\n",
    "# X_train = vectorizer.fit_transform(train_data['FOI_TEXT'])\n",
    "# X_val = vectorizer.transform(val_data['FOI_TEXT'])\n",
    "# X_unlabeled = vectorizer.transform(unlabeled_data['FOI_TEXT'])\n",
    "\n",
    "# y_train = train_data['LABEL']\n",
    "# y_val = val_data['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BioBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Tokenize labeled and unlabeled data\n",
    "labeled_inputs = tokenize_texts(labeled_data['FOI_TEXT'].tolist())\n",
    "unlabeled_inputs = tokenize_texts(unlabeled_data['FOI_TEXT'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 1, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['encoded_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load the BioBERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=len(labeled_data['LABEL'].unique()))\n",
    "\n",
    "# Prepare labels\n",
    "labels = torch.tensor(labeled_data['encoded_label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for the Trainer\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Ensure we return a dictionary that matches the model's input format\n",
    "        return {\n",
    "            'input_ids': self.inputs['input_ids'][idx],\n",
    "            'attention_mask': self.inputs['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]  # Must be included as 'labels'\n",
    "        }\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(labeled_inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9871e5fce795418a84ab41629ccc48de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1965.8232, 'train_samples_per_second': 0.205, 'train_steps_per_second': 0.026, 'train_loss': 1.6527928371055454, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51, training_loss=1.6527928371055454, metrics={'train_runtime': 1965.8232, 'train_samples_per_second': 0.205, 'train_steps_per_second': 0.026, 'total_flos': 106036611412992.0, 'train_loss': 1.6527928371055454, 'epoch': 1.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum iterations and confidence threshold\n",
    "max_iterations = 5\n",
    "confidence_threshold = 0.8\n",
    "previous_pseudo_labels_count = 0\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"Iteration {iteration + 1}/{max_iterations}\")\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Predict on unlabeled data\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**unlabeled_inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # Get high-confidence predictions\n",
    "    high_confidence_indices = (probabilities.max(dim=1)[0] >= confidence_threshold).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    # Filter out high-confidence predictions\n",
    "    pseudo_labels = predictions[high_confidence_indices]\n",
    "    unlabeled_texts = unlabeled_data['text'].tolist()\n",
    "    high_confidence_texts = [unlabeled_texts[i] for i in high_confidence_indices]\n",
    "\n",
    "    # Create a new DataFrame for pseudo-labeled data\n",
    "    pseudo_labeled_data = pd.DataFrame({\n",
    "        'text': high_confidence_texts,\n",
    "        'label': pseudo_labels.tolist()\n",
    "    })\n",
    "\n",
    "    # Stop if no new pseudo-labels are generated\n",
    "    if len(pseudo_labeled_data) == 0:\n",
    "        print(\"No high-confidence pseudo-labels found. Stopping the process.\")\n",
    "        break\n",
    "\n",
    "    # Combine labeled and pseudo-labeled data\n",
    "    combined_data = pd.concat([combined_data, pseudo_labeled_data], ignore_index=True)\n",
    "\n",
    "    # Tokenize the combined dataset\n",
    "    combined_inputs = tokenize_texts(combined_data['text'].tolist())\n",
    "    combined_labels = torch.tensor(combined_data['label'].tolist())\n",
    "\n",
    "    # Create dataset for Trainer\n",
    "    combined_dataset = CustomDataset(combined_inputs, combined_labels)\n",
    "\n",
    "    # Train the model again\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=combined_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Optional: Check if the number of pseudo-labels is improving\n",
    "    new_pseudo_labels_count = len(pseudo_labeled_data)\n",
    "    if new_pseudo_labels_count == previous_pseudo_labels_count:\n",
    "        print(\"No improvement in the number of pseudo-labels. Stopping the process.\")\n",
    "        break\n",
    "    previous_pseudo_labels_count = new_pseudo_labels_count\n",
    "\n",
    "# Final evaluation (optional)\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code (e.g., using metrics like accuracy, precision, recall)\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize new data\n",
    "new_data = ['new_unlabeled_text1', 'new_unlabeled_text2']\n",
    "new_inputs = tokenize_texts(new_data)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**new_inputs)\n",
    "    final_predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "# Output predictions\n",
    "print(final_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
