{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d7a77d-2710-4113-a4e6-95f0fe329bb0",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06244427-b4c1-4d71-b458-0dc66b1dba92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9d94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./data/preprocessed_data.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe\n",
    "df = pd.read_csv(\n",
    "    data_file,  # The data file being read, from the variable assignment above\n",
    "    on_bad_lines=\"warn\",  # This tells Pandas to only warn on bad lines vs causing an error\n",
    "    dtype=\"str\",\n",
    ")  # This tells Pandas to treat all numbers as words\n",
    "\n",
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699caf8a-3dba-41a2-b639-ec5e74a31012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9605, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526595ac-b49e-4cc7-b5e4-e85a32aa6c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MDR_REPORT_KEY</th>\n",
       "      <th>MDR_TEXT_KEY</th>\n",
       "      <th>TEXT_TYPE_CODE</th>\n",
       "      <th>PATIENT_SEQUENCE_NUMBER</th>\n",
       "      <th>DATE_REPORT</th>\n",
       "      <th>FOI_TEXT</th>\n",
       "      <th>DEVICE_EVENT_KEY</th>\n",
       "      <th>IMPLANT_FLAG</th>\n",
       "      <th>DATE_REMOVED_FLAG</th>\n",
       "      <th>...</th>\n",
       "      <th>COMBINATION_PRODUCT_FLAG</th>\n",
       "      <th>UDI-DI</th>\n",
       "      <th>UDI-PUBLIC</th>\n",
       "      <th>TOKENIZED_TEXT</th>\n",
       "      <th>NOPUNCT_TEXT</th>\n",
       "      <th>NOSTOPWORDS_TEXT</th>\n",
       "      <th>NODIGITS_TEXT</th>\n",
       "      <th>POS_TEXT</th>\n",
       "      <th>LEMMATIZED_TEXT</th>\n",
       "      <th>STEMMED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106741</td>\n",
       "      <td>6383024</td>\n",
       "      <td>106903842</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['based', 'on', 'additional', 'information', '...</td>\n",
       "      <td>['based', 'on', 'additional', 'information', '...</td>\n",
       "      <td>['based', 'additional', 'information', 'receiv...</td>\n",
       "      <td>['based', 'additional', 'information', 'receiv...</td>\n",
       "      <td>[('based', 'VBN'), ('additional', 'JJ'), ('inf...</td>\n",
       "      <td>['base', 'additional', 'information', 'receive...</td>\n",
       "      <td>['base', 'addit', 'inform', 'receiv', 'complai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 MDR_REPORT_KEY MDR_TEXT_KEY TEXT_TYPE_CODE  \\\n",
       "0     106741        6383024    106903842              N   \n",
       "\n",
       "  PATIENT_SEQUENCE_NUMBER DATE_REPORT  \\\n",
       "0                       1               \n",
       "\n",
       "                                            FOI_TEXT DEVICE_EVENT_KEY  \\\n",
       "0  BASED ON ADDITIONAL INFORMATION RECEIVED THIS ...                    \n",
       "\n",
       "  IMPLANT_FLAG DATE_REMOVED_FLAG  ... COMBINATION_PRODUCT_FLAG UDI-DI  \\\n",
       "0                                 ...                        N          \n",
       "\n",
       "  UDI-PUBLIC                                     TOKENIZED_TEXT  \\\n",
       "0             ['based', 'on', 'additional', 'information', '...   \n",
       "\n",
       "                                        NOPUNCT_TEXT  \\\n",
       "0  ['based', 'on', 'additional', 'information', '...   \n",
       "\n",
       "                                    NOSTOPWORDS_TEXT  \\\n",
       "0  ['based', 'additional', 'information', 'receiv...   \n",
       "\n",
       "                                       NODIGITS_TEXT  \\\n",
       "0  ['based', 'additional', 'information', 'receiv...   \n",
       "\n",
       "                                            POS_TEXT  \\\n",
       "0  [('based', 'VBN'), ('additional', 'JJ'), ('inf...   \n",
       "\n",
       "                                     LEMMATIZED_TEXT  \\\n",
       "0  ['base', 'additional', 'information', 'receive...   \n",
       "\n",
       "                                        STEMMED_TEXT  \n",
       "0  ['base', 'addit', 'inform', 'receiv', 'complai...  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d52aa9-a028-4efa-86d6-fcfdf16ab2df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['based', 'on', 'additional', 'information', 'received', 'this', 'complaint', 'is', 'not', 'medtronic', 'product', 'if', 'information', 'is', 'provided', 'in', 'the', 'future', 'supplemental', 'report', 'will', 'be', 'issued']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (\n",
    "            gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
    "        )  # deacc=True removes punctuations\n",
    "\n",
    "\n",
    "data = df[\"FOI_TEXT\"].tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c6dce8-129c-47cb-99ef-3ec2dab1d416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(\n",
    "    data_words, min_count=5, threshold=100\n",
    ")  # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448dd175-aee8-4cd8-89cc-97eb0b3f422e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend([\"from\", \"subject\", \"re\", \"edu\", \"use\"])\n",
    "\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in stop_words]\n",
    "        for doc in texts\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "\n",
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append(\n",
    "            [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "        )\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e49f96-dbb0-43ab-9ffe-1022de301796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base', 'additional', 'information', 'receive', 'complaint', 'medtronic', 'product', 'information', 'provide', 'future', 'supplemental', 'report', 'issue']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(\n",
    "    data_words_bigrams, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    ")\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a6de27-4e41-42e4-9280-7da6f2cbe50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['based',\n",
       " 'additional',\n",
       " 'information',\n",
       " 'received',\n",
       " 'complaint',\n",
       " 'medtronic',\n",
       " 'product',\n",
       " 'information',\n",
       " 'provided',\n",
       " 'future',\n",
       " 'supplemental',\n",
       " 'report',\n",
       " 'issued']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5a5d3b-b3f7-45fe-8238-4bc792d1e816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80260b3e-2549-4564-83d8-01dac83f2345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=10,\n",
    "    random_state=100,\n",
    "    chunksize=100,\n",
    "    passes=10,\n",
    "    per_word_topics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b65d281-b7d3-4551-a140-551841d8e4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.150*\"pain\" + 0.113*\"patient\" + 0.107*\"treatment\" + 0.045*\"implant\" + '\n",
      "  '0.029*\"symptom\" + 0.028*\"surgery\" + 0.028*\"include\" + 0.027*\"complication\" '\n",
      "  '+ 0.026*\"pelvic\" + 0.023*\"vaginal\"'),\n",
      " (1,\n",
      "  '0.085*\"patient\" + 0.066*\"report\" + 0.054*\"scientific\" + 0.053*\"procedure\" + '\n",
      "  '0.038*\"corporation\" + 0.035*\"implant\" + 0.029*\"advantage\" + 0.027*\"perform\" '\n",
      "  '+ 0.023*\"experience\" + 0.022*\"mesh\"'),\n",
      " (2,\n",
      "  '0.469*\"choose\" + 0.053*\"number\" + 0.037*\"send\" + 0.028*\"frequent\" + '\n",
      "  '0.027*\"evidence\" + 0.026*\"code\" + 0.022*\"find\" + 0.018*\"slight\" + '\n",
      "  '0.017*\"report\" + 0.017*\"packing\"'),\n",
      " (3,\n",
      "  '0.043*\"vaginal\" + 0.038*\"mesh\" + 0.021*\"bladder\" + 0.017*\"sling\" + '\n",
      "  '0.016*\"cystoscopy\" + 0.015*\"urinary\" + 0.012*\"note\" + 0.011*\"patient\" + '\n",
      "  '0.011*\"anterior\" + 0.010*\"procedure\"'),\n",
      " (4,\n",
      "  '0.067*\"representative\" + 0.067*\"patient\" + 0.064*\"implant\" + 0.063*\"report\" '\n",
      "  '+ 0.047*\"sling\" + 0.046*\"urinary\" + 0.028*\"sphincter\" + 0.027*\"device\" + '\n",
      "  '0.025*\"artificial\" + 0.021*\"due\"'),\n",
      " (5,\n",
      "  '0.085*\"device\" + 0.044*\"available\" + 0.038*\"analysis\" + 0.029*\"review\" + '\n",
      "  '0.025*\"product\" + 0.023*\"base\" + 0.022*\"perform\" + 0.022*\"investigation\" + '\n",
      "  '0.022*\"information\" + 0.020*\"confirm\"'),\n",
      " (6,\n",
      "  '0.123*\"device\" + 0.052*\"therefore\" + 0.050*\"upn\" + 0.049*\"lot\" + '\n",
      "  '0.042*\"complainant\" + 0.041*\"provide\" + 0.038*\"date\" + 0.035*\"complaint\" + '\n",
      "  '0.031*\"return\" + 0.030*\"file\"'),\n",
      " (7,\n",
      "  '0.116*\"provide\" + 0.114*\"report\" + 0.086*\"information\" + 0.054*\"submit\" + '\n",
      "  '0.047*\"supplemental\" + 0.042*\"future\" + 0.029*\"reference\" + 0.028*\"issue\" + '\n",
      "  '0.028*\"source\" + 0.026*\"relevant\"'),\n",
      " (8,\n",
      "  '0.112*\"event\" + 0.089*\"block\" + 0.060*\"code\" + 0.058*\"date\" + '\n",
      "  '0.053*\"patient\" + 0.043*\"capture\" + 0.039*\"reportable\" + 0.032*\"report\" + '\n",
      "  '0.026*\"legal\" + 0.021*\"impact\"'),\n",
      " (9,\n",
      "  '0.058*\"pain\" + 0.050*\"patient\" + 0.016*\"pelvic\" + 0.013*\"medication\" + '\n",
      "  '0.013*\"also\" + 0.010*\"duration\" + 0.009*\"follow\" + 0.009*\"floor\" + '\n",
      "  '0.008*\"symptom\" + 0.008*\"mesh\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3ad16c-2465-4239-b79f-5d668a970459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.5142455499661397\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "# TODO: Pickle these as the baseline models\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence=\"c_v\"\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(\"Coherence Score: \", coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c0fbb86-5174-4c1d-a43c-aa7a36b4e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    # TODO: Pickle each lda_model and coherence_model_lda\n",
    "    lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        random_state=100,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha=a,\n",
    "        eta=b,\n",
    "    )\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence=\"c_v\"\n",
    "    )\n",
    "\n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4177c91a-ad86-4707-a785-2ebc77f1d733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [30:55<00:00, 51.54s/it]   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid[\"Validation_Set\"] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 3\n",
    "max_topics = 5\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "# alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha.append(\"symmetric\")\n",
    "# alpha.append(\"asymmetric\")\n",
    "\n",
    "alpha = [0.01, 0.5, \"symmetric\"]\n",
    "\n",
    "# Beta parameter\n",
    "# beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta.append(\"symmetric\")\n",
    "beta = [0.01, 0.5, \"symmetric\"]\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "\n",
    "corpus_sets = [\n",
    "    gensim.utils.ClippedCorpus(corpus, int(num_of_docs * 0.70)),\n",
    "    gensim.utils.ClippedCorpus(corpus, int(num_of_docs * 0.75)),\n",
    "]\n",
    "\n",
    "corpus_title = [\"70% Corpus\", \"75% Corpus\"]\n",
    "\n",
    "model_results = {\n",
    "    \"Validation_Set\": [],\n",
    "    \"Topics\": [],\n",
    "    \"Alpha\": [],\n",
    "    \"Beta\": [],\n",
    "    \"Coherence\": [],\n",
    "}\n",
    "\n",
    "# Can take a long time to run\n",
    "if True:\n",
    "    pbar = tqdm.tqdm(\n",
    "        total=(len(beta) * len(alpha) * len(topics_range) * len(corpus_title))\n",
    "    )\n",
    "\n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(\n",
    "                        corpus=corpus_sets[i], dictionary=id2word, k=k, a=a, b=b\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results[\"Validation_Set\"].append(corpus_title[i])\n",
    "                    model_results[\"Topics\"].append(k)\n",
    "                    model_results[\"Alpha\"].append(a)\n",
    "                    model_results[\"Beta\"].append(b)\n",
    "                    model_results[\"Coherence\"].append(cv)\n",
    "\n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv(\n",
    "        f\"./data/lda_tuning_results.csv\", index=False\n",
    "    )\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85d129-de7d-4cca-ac0a-1984b042ca5c",
   "metadata": {},
   "source": [
    "## Start of Analysis Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9be61b-b1ec-4f7a-9c33-a5b55a73294a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_results_df = pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8deed7-cc52-4cbe-a84b-02fd0eb3c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "TAG = f\"{datetime.datetime.now():%Y-%m-%d-%s}\"\n",
    "\n",
    "with open(\n",
    "    f\"./data/model_results_df-{max_topics}-topics-{TAG}.pickle\", \"wb\"\n",
    ") as f:\n",
    "    pickle.dump(model_results_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292f74b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58dc6ad-9079-4033-9846-c9a82e476776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.581722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.585841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.598325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.579251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.581705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.584441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.579850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.588638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.588638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.557099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.534387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.644442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.590109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.547055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.567366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.571914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.638525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.638525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.575566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.584577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.593841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.585426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.582060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.582060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.573014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.582060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.551688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.589463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.595514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.545398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.564751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.541112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.565656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.635027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validation_Set  Topics      Alpha       Beta  Coherence\n",
       "0      70% Corpus       3       0.01       0.01   0.581722\n",
       "1      70% Corpus       3       0.01        0.5   0.585841\n",
       "2      70% Corpus       3       0.01  symmetric   0.598325\n",
       "3      70% Corpus       3        0.5       0.01   0.579251\n",
       "4      70% Corpus       3        0.5        0.5   0.581705\n",
       "5      70% Corpus       3        0.5  symmetric   0.584441\n",
       "6      70% Corpus       3  symmetric       0.01   0.579850\n",
       "7      70% Corpus       3  symmetric        0.5   0.588638\n",
       "8      70% Corpus       3  symmetric  symmetric   0.588638\n",
       "9      70% Corpus       4       0.01       0.01   0.557099\n",
       "10     70% Corpus       4       0.01        0.5   0.534387\n",
       "11     70% Corpus       4       0.01  symmetric   0.644442\n",
       "12     70% Corpus       4        0.5       0.01   0.590109\n",
       "13     70% Corpus       4        0.5        0.5   0.547055\n",
       "14     70% Corpus       4        0.5  symmetric   0.567366\n",
       "15     70% Corpus       4  symmetric       0.01   0.571914\n",
       "16     70% Corpus       4  symmetric        0.5   0.638525\n",
       "17     70% Corpus       4  symmetric  symmetric   0.638525\n",
       "18     75% Corpus       3       0.01       0.01   0.575566\n",
       "19     75% Corpus       3       0.01        0.5   0.584577\n",
       "20     75% Corpus       3       0.01  symmetric   0.593841\n",
       "21     75% Corpus       3        0.5       0.01   0.585426\n",
       "22     75% Corpus       3        0.5        0.5   0.582060\n",
       "23     75% Corpus       3        0.5  symmetric   0.582060\n",
       "24     75% Corpus       3  symmetric       0.01   0.573014\n",
       "25     75% Corpus       3  symmetric        0.5   0.583371\n",
       "26     75% Corpus       3  symmetric  symmetric   0.582060\n",
       "27     75% Corpus       4       0.01       0.01   0.562056\n",
       "28     75% Corpus       4       0.01        0.5   0.551688\n",
       "29     75% Corpus       4       0.01  symmetric   0.589463\n",
       "30     75% Corpus       4        0.5       0.01   0.595514\n",
       "31     75% Corpus       4        0.5        0.5   0.545398\n",
       "32     75% Corpus       4        0.5  symmetric   0.564751\n",
       "33     75% Corpus       4  symmetric       0.01   0.541112\n",
       "34     75% Corpus       4  symmetric        0.5   0.565656\n",
       "35     75% Corpus       4  symmetric  symmetric   0.635027"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Graph the coherence scores based on some common criteria\n",
    "model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcfa2d90-e160-4a3c-b9a7-75a2f6022a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_topics = 4\n",
    "alpha = 0.01\n",
    "beta = \"symmetric\"\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    random_state=100,\n",
    "    chunksize=100,\n",
    "    passes=10,\n",
    "    alpha=alpha,\n",
    "    eta=beta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8327b23-62a6-42ba-a19d-0dc07401c49d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_data_filepath = os.path.join(\n",
    "    f\"./data/ldavis_tuned_{num_topics}-topics-{TAG}.pickle\"\n",
    ")\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if True:\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, \"wb\") as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, \"rb\") as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(\n",
    "    LDAvis_prepared,\n",
    "    f\"./data/ldavis_tuned_{num_topics}-topics-{TAG}\"\n",
    "    + str(num_topics)\n",
    "    + \".html\",\n",
    ")\n",
    "\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
